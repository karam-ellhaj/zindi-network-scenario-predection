{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport os \nfrom sklearn.model_selection import GroupKFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats","metadata":{"execution":{"iopub.status.busy":"2023-09-10T19:43:16.787611Z","iopub.execute_input":"2023-09-10T19:43:16.788012Z","iopub.status.idle":"2023-09-10T19:43:20.575831Z","shell.execute_reply.started":"2023-09-10T19:43:16.787977Z","shell.execute_reply":"2023-09-10T19:43:20.574471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = os.listdir('/kaggle/input/network-scenario/Train_data(1)/Train_data')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T19:43:20.578090Z","iopub.execute_input":"2023-09-10T19:43:20.578719Z","iopub.status.idle":"2023-09-10T19:43:20.617888Z","shell.execute_reply.started":"2023-09-10T19:43:20.578674Z","shell.execute_reply":"2023-09-10T19:43:20.616932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sets = [pd.read_csv('/kaggle/input/network-scenario/Train_data(1)/Train_data/'+i) for i in files]\n\n# test data \ntest_file = os.listdir('/kaggle/input/network-scenario/Test_data/Test_data')\ntest_sets = [pd.read_csv('/kaggle/input/network-scenario/Test_data/Test_data/'+i) for i in test_file]","metadata":{"execution":{"iopub.status.busy":"2023-09-10T19:43:20.619012Z","iopub.execute_input":"2023-09-10T19:43:20.619448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i  in range(test_file.__len__()) :\n    test_file[i] = test_file[i].removesuffix('.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature engineering for the testing data that requires to trait every network scenario indevualy \nfor i in range(test_sets.__len__()):\n    #lag features\n    test_sets[i]['prtpktin_lag1'] = test_sets[i]['portPktIn'].shift(1)\n    test_sets[i]['prtpktout_lag1'] = test_sets[i]['portPktOut'].shift(1)\n    test_sets[i]['qSize_lag'] = test_sets[i]['qSize'].shift(1)\n    \n    test_sets[i]['prtpktin_lag2'] = test_sets[i]['portPktIn'].shift(2)\n    test_sets[i]['prtpktout_lag2'] = test_sets[i]['portPktOut'].shift(2)\n    test_sets[i]['qSize_lag2'] = test_sets[i]['qSize'].shift(2)\n    \n    test_sets[i]['prtpktin_lag3'] = test_sets[i]['portPktIn'].shift(3)\n    test_sets[i]['prtpktout_lag3'] = test_sets[i]['portPktOut'].shift(3)\n    test_sets[i]['qSize_lag3']= test_sets[i]['qSize'].shift(3)\n    \n    test_sets[i]['prtpktin_lag4'] = test_sets[i]['portPktIn'].shift(4)\n    test_sets[i]['prtpktout_lag4'] = test_sets[i]['portPktOut'].shift(4)\n    test_sets[i]['qSize_lag4']= test_sets[i]['qSize'].shift(4)\n    \n    test_sets[i]['prtpktin_lag5'] = test_sets[i]['portPktIn'].shift(5)\n    test_sets[i]['prtpktout_lag5'] = test_sets[i]['portPktOut'].shift(5)\n    test_sets[i]['qSize_lag5']= test_sets[i]['qSize'].shift(5)\n    \n    #future features\n    test_sets[i]['prtpktin_forword'] = test_sets[i]['portPktIn'].shift(-1)\n    test_sets[i]['prtpktout_forword'] = test_sets[i]['portPktOut'].shift(-1)\n    test_sets[i]['qSize_forword'] = test_sets[i]['qSize'].shift(-1)\n    \n    test_sets[i]['prtpktin_forword2'] = test_sets[i]['portPktIn'].shift(-2)\n    test_sets[i]['prtpktout_forword2'] = test_sets[i]['portPktOut'].shift(-2)\n    test_sets[i]['qSize_forword2'] = test_sets[i]['qSize'].shift(-2)\n    \n    test_sets[i]['prtpktin_forword3'] = test_sets[i]['portPktIn'].shift(-3)\n    test_sets[i]['prtpktout_forword3'] = test_sets[i]['portPktOut'].shift(-3)\n    test_sets[i]['qSize_forword3'] = test_sets[i]['qSize'].shift(-3)\n    \n    test_sets[i]['prtpktin_forword4'] = test_sets[i]['portPktIn'].shift(-4)\n    test_sets[i]['prtpktout_forword4'] = test_sets[i]['portPktOut'].shift(-4)\n    test_sets[i]['qSize_forword4'] = test_sets[i]['qSize'].shift(-4)\n    \n    test_sets[i]['prtpktin_forword5'] = test_sets[i]['portPktIn'].shift(-5)\n    test_sets[i]['prtpktout_forword5'] = test_sets[i]['portPktOut'].shift(-5)\n    test_sets[i]['qSize_forword5'] = test_sets[i]['qSize'].shift(-5)\n    \n    \n    test_sets[i]['group'] = test_file[i] + '_'  + test_sets[i]['time'].apply(lambda x:str(x))\n    test_sets[i]['time_in_sec'] = test_sets[i]['time'].apply(lambda x: (x/1000).__trunc__()) \n    #aggregation\n    agg = np.array(test_sets[i].drop(columns = 'group').groupby('time_in_sec').aggregate('mean')['portPktIn'])\n    test_sets[i]['in_ts'] = agg[test_sets[i]['time_in_sec']]\n    \n    agg = np.array(test_sets[i].drop(columns = 'group').groupby('time_in_sec').aggregate('mean')['portPktOut'])\n    test_sets[i]['out_ts'] = agg[test_sets[i]['time_in_sec']]\n    \n    agg = np.array(test_sets[i].drop(columns = 'group').groupby('time_in_sec').aggregate('mean')['qSize'])\n    test_sets[i]['qSize_agg'] = agg[test_sets[i]['time_in_sec']]\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature engineering for the training data that requires to trait every network scenario indevualy \n\nfor i in range(train_sets.__len__()):\n    train_sets[i]['prtpktin_lag1'] = train_sets[i]['portPktIn'].shift(1)\n    train_sets[i]['prtpktout_lag1'] = train_sets[i]['portPktOut'].shift(1)\n    train_sets[i]['qSize_lag'] = train_sets[i]['qSize'].shift(1)\n    \n    train_sets[i]['prtpktin_lag2'] = train_sets[i]['portPktIn'].shift(2)\n    train_sets[i]['prtpktout_lag2'] = train_sets[i]['portPktOut'].shift(2)\n    train_sets[i]['qSize_lag2'] = train_sets[i]['qSize'].shift(2)\n    \n    train_sets[i]['prtpktin_lag3'] = train_sets[i]['portPktIn'].shift(3)\n    train_sets[i]['prtpktout_lag3'] = train_sets[i]['portPktOut'].shift(3)\n    train_sets[i]['qSize_lag3'] = train_sets[i]['qSize'].shift(3)\n    \n    train_sets[i]['prtpktin_lag4'] = train_sets[i]['portPktIn'].shift(4)\n    train_sets[i]['prtpktout_lag4'] = train_sets[i]['portPktOut'].shift(4)\n    train_sets[i]['qSize_lag4'] = train_sets[i]['qSize'].shift(4)\n    \n    train_sets[i]['prtpktin_lag5'] = train_sets[i]['portPktIn'].shift(5)\n    train_sets[i]['prtpktout_lag5'] = train_sets[i]['portPktOut'].shift(5)\n    train_sets[i]['qSize_lag5'] = train_sets[i]['qSize'].shift(5)\n    \n    train_sets[i]['prtpktin_forword'] = train_sets[i]['portPktIn'].shift(-1)\n    train_sets[i]['prtpktout_forword'] = train_sets[i]['portPktOut'].shift(-1)\n    train_sets[i]['qSize_forword'] = train_sets[i]['qSize'].shift(-1)\n    \n    train_sets[i]['prtpktin_forword2'] = train_sets[i]['portPktIn'].shift(-2)\n    train_sets[i]['prtpktout_forword2'] = train_sets[i]['portPktOut'].shift(-2)\n    train_sets[i]['qSize_forword2'] = train_sets[i]['qSize'].shift(-2)\n    \n    train_sets[i]['prtpktin_forword3'] = train_sets[i]['portPktIn'].shift(-3)\n    train_sets[i]['prtpktout_forword3'] = train_sets[i]['portPktOut'].shift(-3)\n    train_sets[i]['qSize_forword3'] = train_sets[i]['qSize'].shift(-3)\n    \n    train_sets[i]['prtpktin_forword4'] = train_sets[i]['portPktIn'].shift(-4)\n    train_sets[i]['prtpktout_forword4'] = train_sets[i]['portPktOut'].shift(-4)\n    train_sets[i]['qSize_forword4'] = train_sets[i]['qSize'].shift(-4)\n    \n    train_sets[i]['prtpktin_forword5'] = train_sets[i]['portPktIn'].shift(-5)\n    train_sets[i]['prtpktout_forword5'] = train_sets[i]['portPktOut'].shift(-5)\n    train_sets[i]['qSize_forword5'] = train_sets[i]['qSize'].shift(-5)\n    \n    \n    train_sets[i]['time_in_sec'] = train_sets[i]['time'].apply(lambda x: (x/1000).__trunc__())  \n    agg = np.array(train_sets[i].groupby('time_in_sec').aggregate('mean')['portPktIn'])\n    train_sets[i]['in_ts'] = agg[train_sets[i]['time_in_sec']]\n    \n    agg = np.array(train_sets[i].groupby('time_in_sec').aggregate('mean')['portPktOut'])\n    train_sets[i]['out_ts'] = agg[train_sets[i]['time_in_sec']]\n    \n    agg = np.array(train_sets[i].groupby('time_in_sec').aggregate('mean')['qSize'])\n    train_sets[i]['qSize_agg'] = agg[train_sets[i]['time_in_sec']]\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat(train_sets)\ntest = pd.concat(test_sets)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['in_out_mean'] = (train['portPktIn'] + train['portPktOut'])/2\ntest['in_out_mean'] = (test['portPktIn'] + test['portPktOut'])/2\n\ntrain['in_out_ts_mean'] = (train['in_ts']+train['out_ts'])/2\ntest['in_out_ts_mean'] = (test['in_ts']+test['out_ts'])/2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id = test['group']\nid = id.apply(lambda x:x.lower())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(columns=['group'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns=['label'],inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns ='time',inplace=True)\ntest.drop(columns ='time', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb = LGBMClassifier(random_state=42)\nlgb.fit(X=train,y=y)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = lgb.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submition = pd.DataFrame({\n    'ID':id,\n    'Target':prediction\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submition.set_index('ID',inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submition.to_csv('/kaggle/working/submission-cv87.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submition","metadata":{"execution":{"iopub.status.busy":"2023-09-10T21:41:29.249753Z","iopub.execute_input":"2023-09-10T21:41:29.249967Z","iopub.status.idle":"2023-09-10T21:41:29.513304Z","shell.execute_reply.started":"2023-09-10T21:41:29.249946Z","shell.execute_reply":"2023-09-10T21:41:29.512380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}